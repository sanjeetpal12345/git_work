{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c92730d-edf0-4be8-8d75-a450a27234bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51da35bd-c93d-4915-beda-1205cdf89894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the word to find:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'C:\\Users\\hp.DESKTOP-MTCIJR8\\Videos\\dfccil\\workbackup_pc_list.txt' not found.\n",
      "File 'C:\\Users\\hp.DESKTOP-MTCIJR8\\Videos\\dfccil\\PC_Allotment_20_08_2024.txt' not found.\n",
      "The word 'hello' is NOT present in both files.\n"
     ]
    }
   ],
   "source": [
    "# Function to read the contents of a file and return a set of words\n",
    "def get_words_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read().lower()  # Read and convert content to lowercase\n",
    "            words = set(content.split())   # Split content into words and create a set\n",
    "            return words\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "        return set()\n",
    "\n",
    "# Function to check if a particular word is present in both files\n",
    "def find_word_in_both_files(file1_path, file2_path, word):\n",
    "    words_file1 = get_words_from_file(file1_path)\n",
    "    words_file2 = get_words_from_file(file2_path)\n",
    "    \n",
    "    # Check if the word is in both sets\n",
    "    if word.lower() in words_file1 and word.lower() in words_file2:\n",
    "        print(f\"The word '{word}' is present in both files.\")\n",
    "    else:\n",
    "        print(f\"The word '{word}' is NOT present in both files.\")\n",
    "\n",
    "# Specify the paths to the two text files\n",
    "file1_path = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\workbackup_pc_list.txt'\n",
    "file2_path = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\PC_Allotment_20_08_2024.txt'\n",
    "\n",
    "# Input the word to search for\n",
    "word_to_find = input(\"Enter the word to find: \")\n",
    "\n",
    "# Call the function to check for the word in both files\n",
    "find_word_in_both_files(file1_path, file2_path, word_to_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22f0504-0ddb-400b-91b8-1507b7c6687e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'C:\\Users\\hp.DESKTOP-MTCIJR8\\Videos\\dfccil\\work\\backup_pc_list.txt' not found.\n",
      "No common words found in both files.\n"
     ]
    }
   ],
   "source": [
    "# Function to read the contents of a file and return a set of words\n",
    "def get_words_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read().lower()  # Read and convert content to lowercase\n",
    "            words = set(content.split())   # Split content into words and create a set\n",
    "            return words\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "        return set()\n",
    "\n",
    "# Function to find all words that are available in both files\n",
    "def find_common_words(file1_path, file2_path):\n",
    "    words_file1 = get_words_from_file(file1_path)\n",
    "    words_file2 = get_words_from_file(file2_path)\n",
    "    \n",
    "    # Find the intersection of the two sets\n",
    "    common_words = words_file1.intersection(words_file2)\n",
    "    \n",
    "    if common_words:\n",
    "        print(f\"Words available in both files: {', '.join(sorted(common_words))}\")\n",
    "    else:\n",
    "        print(\"No common words found in both files.\")\n",
    "\n",
    "# Specify the paths to the two text files\n",
    "file1_path = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\backup_pc_list.txt'\n",
    "file2_path = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\PC_Allotment_20_08_2024.txt'\n",
    "\n",
    "# Call the function to find common words in both files\n",
    "find_common_words(file1_path, file2_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac43a434-cc27-4963-8933-4186b549d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words: {'pg01eh88', 'ina8310krq', 'hello'}\n"
     ]
    }
   ],
   "source": [
    "# list of common serial no available in previous buyback list and current made list\n",
    "file_path1 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\current_buyback_old_pc_list.txt'\n",
    "file_path2 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\PC_Allotment_20_08_2024_previous.txt'\n",
    "\n",
    "# Read the content of the files\n",
    "with open(file_path1, 'r', encoding='utf-8') as file1:\n",
    "    content1 = file1.read().lower()\n",
    "\n",
    "with open(file_path2, 'r', encoding='utf-8') as file2:\n",
    "    content2 = file2.read().lower()\n",
    "\n",
    "# Tokenize the content into words\n",
    "words1 = set(content1.split())\n",
    "words2 = set(content2.split())\n",
    "\n",
    "# Find common words\n",
    "common_words = words1.intersection(words2)\n",
    "\n",
    "# Print the common words\n",
    "print(\"Common words:\", common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e267177d-52c3-4e16-b975-7b596d10b775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758bcc7-8c09-49b7-b819-5426de9336c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359463bd-04d1-4c94-bc10-78add7ea91e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words that appear more than once: ['pg005mkh', 'ina150xygn', 'pg0003cg', 'pg00bqol', 'pg83652', 'ina8370v1m', 'sgh9300r6l', '1087az114447', 'ina828083j', 'ina201yhhz', 'ina8370xg7', 'ina023080q', 'sgh9300r57', 'ina93303xm', 'ini73203ng', '36gvxc2', 'r8x6c7n', 'pg00bq26', 'pg004435', 'pg00bq2b', 'pg005mk6', 'pg00bq4n', '1s0164a2qr8x6dom', 'ina201yhdv', 'pg00bq40', 'uxb1jsih08h3455836', 'ina201yhhh', 'pg00bq4k', 'ina9500b11', 'ina0160hcy', 'pg00bq4f', 'l92be36', 'ina137tz4p', 'ina137tz57', 'l92al75', 'pg0003b4', 'pg0003d8', 'pg00442n', 'l92be64', 'ina109vjbj', 'pg00bq4m']\n"
     ]
    }
   ],
   "source": [
    "# list of double entries made in  previous buyback list\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\PC_Allotment_20_08_2024.txt'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read().lower()\n",
    "\n",
    "# Tokenize the content into words\n",
    "words = content.split()\n",
    "\n",
    "# Count the frequency of each word\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Find words that appear more than once\n",
    "common_words = [word for word, count in word_counts.items() if count > 1]\n",
    "\n",
    "# Print the common words\n",
    "print(\"Common words that appear more than once:\", common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa4a32-37a6-41b1-b88e-780c4ab1bb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a5664e-1948-4571-9176-796a5adb9d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n",
      "                serial_no\n",
      "0                 dgqyxc2\n",
      "1                pg01eh8g\n",
      "2                 dgqvxc2\n",
      "3              ina149xsw7\n",
      "4                pg010r57\n",
      "..                    ...\n",
      "142               dgr0yc2\n",
      "143            8cc61305s5\n",
      "144              pg017dqh\n",
      "145              pg00bq45\n",
      "146  mk15k-1119w3-1311443\n",
      "\n",
      "[147 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# list of common serial no available in previous buyback list and current made list\n",
    "import pandas as pd\n",
    "file_path1 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\current_buyback_old_pc_list.txt'\n",
    "file_path2 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\list_available.txt'\n",
    "\n",
    "# Read the content of the files\n",
    "with open(file_path1, 'r', encoding='utf-8') as file1:\n",
    "    content1 = file1.read().lower()\n",
    "\n",
    "with open(file_path2, 'r', encoding='utf-8') as file2:\n",
    "    content2 = file2.read().lower()\n",
    "\n",
    "# Tokenize the content into words\n",
    "words1 = set(content1.split())\n",
    "words2 = set(content2.split())\n",
    "\n",
    "# Find common words\n",
    "common_words = words1.intersection(words2)\n",
    "\n",
    "# Print the common words\n",
    "print(type(common_words))\n",
    "#print(\"Common words:\", common_words)\n",
    "df = pd.DataFrame(common_words, columns=['serial_no'])\n",
    "file_path = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\list_available_match_data.txt'\n",
    "\n",
    "# Write the data to the file\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    for item in common_words:\n",
    "        file.write(f\"{item}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65b52b-4ec6-457c-8ff0-87483954cc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a7e0ce-890e-4aa3-bb15-f8d63ce7c193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe5b338d-372f-45e7-903c-69c4da4276b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words not common in both files:\n",
      "{'pg00bq0j', 'pg00h1tm', 'dgm1yc2', 'pg83683', 'pg00h1mn', 'pg00bq3w', 'hello'}\n"
     ]
    }
   ],
   "source": [
    "# compare two txt files and find the list of string not common in both the files\n",
    "import pandas as pd\n",
    "# Define the file paths\n",
    "file_path1 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\list_available_match_data.txt'\n",
    "file_path2 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\current_buyback_old_pc_list.txt'\n",
    "\n",
    "# Read the content of the first file\n",
    "with open(file_path1, 'r', encoding='utf-8') as file1:\n",
    "    content1 = file1.read().lower()\n",
    "\n",
    "# Read the content of the second file\n",
    "with open(file_path2, 'r', encoding='utf-8') as file2:\n",
    "    content2 = file2.read().lower()\n",
    "\n",
    "# Tokenize the content into words and convert to sets\n",
    "words1 = set(content1.split())\n",
    "words2 = set(content2.split())\n",
    "\n",
    "# Find words that are not common in both files\n",
    "unique_to_file1 = words1 - words2\n",
    "unique_to_file2 = words2 - words1\n",
    "\n",
    "# Combine the unique words from both files\n",
    "unique_words = unique_to_file1.union(unique_to_file2)\n",
    "\n",
    "# Print the result\n",
    "print(\"Words not common in both files:\")\n",
    "print(unique_words)\n",
    "df = pd.DataFrame(common_words, columns=['serial_no'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d465d9a-90be-4c78-960e-d018f4e19cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f21d2454-ec64-4411-bcff-49dee5b7376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             serial_no\n",
      "0             pg005mkg\n",
      "1             pg00zz57\n",
      "2           ina128r2fs\n",
      "3             pg017dnz\n",
      "4           ina149xsw7\n",
      "5             pg00h1mn\n",
      "6             pg017dnl\n",
      "7             pg00bq16\n",
      "8             pg0170pr\n",
      "9             pg00zz61\n",
      "10            pg010r56\n",
      "11            pg010r7s\n",
      "12            pg010r6l\n",
      "13            pg00a7qt\n",
      "14            pg00h1ms\n",
      "15             dgm1yc2\n",
      "16             36b0yc2\n",
      "17             36btxc2\n",
      "18             dgpzxc2\n",
      "19            pg017dqz\n",
      "20            pg00h1n1\n",
      "21  uxb1js1h08h3455836\n",
      "22            pg01eh8a\n",
      "23             368zxc2\n",
      "24             dgnsxc2\n",
      "25             dgn0yc2\n",
      "26             dgmzxc2\n",
      "27             dgqwxc2\n",
      "28  uxb1jsih08h3455832\n",
      "29            pg01eh8m\n",
      "30             36fsxc2\n",
      "31             369vxc2\n",
      "32             dgnxxc2\n",
      "33            pg017drs\n",
      "34            pg0003n2\n",
      "35          ina137tz4f\n",
      "36             dgpsxc2\n",
      "37             dglwxc2\n",
      "38            pg01eh8n\n",
      "39             dgptxc2\n",
      "40             l92be34\n",
      "41             36fxxc2\n",
      "42            pg00bq0j\n",
      "43            pg00h1tm\n",
      "44             dgnwxc2\n",
      "Common words: {'pg005mkg', 'pg00zz57', 'ina128r2fs', 'pg017dnz', 'ina149xsw7', 'pg00h1mn', 'pg017dnl', 'pg00bq16', 'pg0170pr', 'pg00zz61', 'pg010r56', 'pg010r7s', 'pg010r6l', 'pg00a7qt', 'pg00h1ms', 'dgm1yc2', '36b0yc2', '36btxc2', 'dgpzxc2', 'pg017dqz', 'pg00h1n1', 'uxb1js1h08h3455836', 'pg01eh8a', '368zxc2', 'dgnsxc2', 'dgn0yc2', 'dgmzxc2', 'dgqwxc2', 'uxb1jsih08h3455832', 'pg01eh8m', '36fsxc2', '369vxc2', 'dgnxxc2', 'pg017drs', 'pg0003n2', 'ina137tz4f', 'dgpsxc2', 'dglwxc2', 'pg01eh8n', 'dgptxc2', 'l92be34', '36fxxc2', 'pg00bq0j', 'pg00h1tm', 'dgnwxc2'}\n"
     ]
    }
   ],
   "source": [
    "# list of common serial no available in previous buyback list and current made list\n",
    "import pandas as pd\n",
    "file_path1 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\current_buyback_old_pc_list.txt'\n",
    "file_path2 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\working_nonworking_pc.txt'\n",
    "\n",
    "# Read the content of the files\n",
    "with open(file_path1, 'r', encoding='utf-8') as file1:\n",
    "    content1 = file1.read().lower()\n",
    "\n",
    "with open(file_path2, 'r', encoding='utf-8') as file2:\n",
    "    content2 = file2.read().lower()\n",
    "\n",
    "# Tokenize the content into words\n",
    "words1 = set(content1.split())\n",
    "words2 = set(content2.split())\n",
    "\n",
    "# Find common words\n",
    "common_words = words1.intersection(words2)\n",
    "df = pd.DataFrame(common_words, columns=['serial_no'])\n",
    "print(df)\n",
    "# Print the common words\n",
    "print(\"Common words:\", common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc99391-6add-4da5-8b35-a69a76c2cba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c41b8f8-e037-4a3b-946d-6eb2ca2049a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words that appear more than once: ['pg005mkh', 'ina150xygn', 'pg0003cg', 'pg00bqol', 'pg83652', 'ina8370v1m', 'sgh9300r6l', '1087az114447', 'ina828083j', 'ina201yhhz', 'ina8370xg7', 'ina023080q', 'sgh9300r57', 'ina93303xm', 'ini73203ng', '36gvxc2', 'r8x6c7n', 'pg00bq26', 'pg004435', 'pg00bq2b', 'pg005mk6', 'pg00bq4n', '1s0164a2qr8x6dom', 'ina201yhdv', 'pg00bq40', 'uxb1jsih08h3455836', 'ina201yhhh', 'pg00bq4k', 'ina9500b11', 'ina0160hcy', 'pg00bq4f', 'l92be36', 'ina137tz4p', 'ina137tz57', 'l92al75', 'pg0003b4', 'pg0003d8', 'pg00442n', 'l92be64', 'ina109vjbj', 'pg00bq4m']\n"
     ]
    }
   ],
   "source": [
    "# list of double entries made in  current buyback list\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\PC_Allotment_20_08_2024_previous.txt'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read().lower()\n",
    "\n",
    "# Tokenize the content into words\n",
    "words = content.split()\n",
    "\n",
    "# Count the frequency of each word\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Find words that appear more than once\n",
    "common_words = [word for word, count in word_counts.items() if count > 1]\n",
    "\n",
    "# Print the common words\n",
    "print(\"Common words that appear more than once:\", common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba746bf-d6d4-4f9f-90e2-075877b56580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bfd67-945a-4c35-88f0-ace5d8cd8612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790adec2-2aa1-4cc7-b2ed-1c7a99a9ff9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900d228-8f55-45f5-8032-2c2cc3e2b639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2e23aa5-7b7f-4feb-816e-1edabcbd55b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                serial_no\n",
      "0                 dgqyxc2\n",
      "1                pg01eh8g\n",
      "2                 dgqvxc2\n",
      "3              ina149xsw7\n",
      "4                pg010r57\n",
      "..                    ...\n",
      "125               dgr0yc2\n",
      "126            8cc61305s5\n",
      "127              pg017dqh\n",
      "128              pg00bq45\n",
      "129  mk15k-1119w3-1311443\n",
      "\n",
      "[130 rows x 1 columns]\n",
      "Common words: {'dgqyxc2', 'pg01eh8g', 'dgqvxc2', 'ina149xsw7', 'pg010r57', '8cg9230wlj', 'pg017dnl', 'pg00bq16', 'pg00zz61', 'pg00a7qk', 'uxb1jsih08h3455824', '8cg9231fcx', 'pg00zz5y', 'dgqsxc2', '36g1yc2', '8cg912125k', 'pg01eh8b', 'mk15k-1119w3-1311454', '8cc61305s6', 'dgqxxc2', 'dgpzxc2', 'pg017dp7', 'dgpyxc2', '8cg9255j1m', 'pg017dr9', 'l92be80', 'pg010r5j', 'pg01eh8l', '8cg9174bvf', 'l92be91', '8cg9255j2n', 'dgkwxc2', '367wxc2', 'pg83683', '36fxxc2', 'pg005mkg', 'pg00h1mn', 'pg00bq18', 'pg010r7c', 'pg017dpt', 'pg0170pr', 'pg010r7s', 'pg00a7qt', '8cg9212l93', 'pg00zz59', 'pg017dne', 'dgpvxc2', '36b0yc2', 'pg00bq3w', 'dgnsxc2', 'pg01eh8j', 'dgqwxc2', 'pg010r6m', 'pg01eh8f', 'pg00bq0h', '8cg9255j37', 'pg010r7r', '36fsxc2', 'pg01eh8e', 'dgnyxc2', 'pg0003n2', 'ina137tz4f', 'pg01eh8n', 'pg00h1tm', '8cg9255j08', '36bxxc2', 'pg00zz57', 'ina128r2fs', 'pg010r56', 'dgqtxc2', 'pg010r5d', 'pg00zz5h', 'pg017drt', 'pg017dp6', 'pg017dqt', 'pg00h1vl', '8cg9174cnf', 'pg00bq1t', 'pg017drp', 'dgmwxc2', 'uxb1jsih08h3455832', 'pg00zz51', 'pg017drs', 'l92be34', '36btxc2', 'dgnwxc2', 'pg83594', 'mk15k-1119w3-1311461', 'dgq0yc2', 'pg017dnz', 'pg01eh8h', '8cg9174cp6', 'pg010r6l', 'pg00h1ms', '8cg9255j0j', 'dgm1yc2', '8cg9255j1y', '8cg9086mdo', 'pg01eh8c', 'pg017dnv', '8cg9174by9', 'pg017dqz', '36dtxc2', 'pg010r5c', 'pg00h1n1', 'pg017dru', '8cg9255j1b', 'pg01eh8a', '368zxc2', '8cg9231fh5', 'pg01eh88', 'dgmzxc2', '8cg9174cpb', 'pg017dng', 'pg01eh8m', 'pg017dq8', 'pg00zz5f', '369vxc2', 'dgnzxc2', 'dgnxxc2', 'dgpsxc2', '36dyxc2', 'dgpwxc2', 'pg00bq0j', 'dglwxc2', 'dgr0yc2', '8cc61305s5', 'pg017dqh', 'pg00bq45', 'mk15k-1119w3-1311443'}\n"
     ]
    }
   ],
   "source": [
    "# list of common serial no available in current buyback list and ledger list\n",
    "import pandas as pd\n",
    "file_path1 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\current_buyback_old_pc_list.txt'\n",
    "file_path2 = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\ledger_SN.txt'\n",
    "\n",
    "# Read the content of the files\n",
    "with open(file_path1, 'r', encoding='utf-8') as file1:\n",
    "    content1 = file1.read().lower()\n",
    "\n",
    "with open(file_path2, 'r', encoding='utf-8') as file2:\n",
    "    content2 = file2.read().lower()\n",
    "\n",
    "# Tokenize the content into words\n",
    "words1 = set(content1.split())\n",
    "words2 = set(content2.split())\n",
    "\n",
    "# Find common words\n",
    "common_words = words1.intersection(words2)\n",
    "df = pd.DataFrame(common_words, columns=['serial_no'])\n",
    "print(df)\n",
    "# Print the common words\n",
    "print(\"Common words:\", common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae3f9a-dc2f-4eda-b48e-7ee5773cb3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1baf3de-d065-46d3-9289-0e5a623ecaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words that appear more than once: []\n"
     ]
    }
   ],
   "source": [
    "# list of double entries made in  current buyback list\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\ledger_SN.txt'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read().lower()\n",
    "\n",
    "# Tokenize the content into words\n",
    "words = content.split()\n",
    "\n",
    "# Count the frequency of each word\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Find words that appear more than once\n",
    "common_words = [word for word, count in word_counts.items() if count > 1]\n",
    "\n",
    "# Print the common words\n",
    "print(\"Common words that appear more than once:\", common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4741af6c-1962-4c14-b711-65e8a09e9774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words that appear more than once: ['pg00h1sa', 'dgm1yc2', 'dglwxc2', 'ina128r2gx']\n"
     ]
    }
   ],
   "source": [
    "# list of double entries made in  current buyback list\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'C:\\\\Users\\\\hp.DESKTOP-MTCIJR8\\\\Videos\\\\dfccil\\\\work\\\\ATC29_6_Sumit.txt'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read().lower()\n",
    "\n",
    "# Tokenize the content into words\n",
    "words = content.split()\n",
    "\n",
    "# Count the frequency of each word\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Find words that appear more than once\n",
    "common_words = [word for word, count in word_counts.items() if count > 1]\n",
    "\n",
    "# Print the common words\n",
    "print(\"Common words that appear more than once:\", common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a19059-1b08-4388-9657-8af3df18b10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24458a67-451f-4d04-84d8-f1b0538d0287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d9ce9-ace3-49c6-b588-5eb564a12566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e34ee-e7c1-413f-ba21-34537e7e4ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea89d37-bf2c-4191-a889-6adc2da3ef02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532d693-c8bf-409b-a87f-cd0b57453836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
